{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a923308",
   "metadata": {},
   "source": [
    "#Thanks to: https://pythonology.eu/a-rag-web-scraper-with-langchain-ollama-and-chroma/\n",
    "\n",
    "Getting repo readme context, applied to:\n",
    "\n",
    "1. https://github.com/JAlcocerT/Streamlit-MultiChat\n",
    "2. https://github.com/qatrackplus/qatrackplus/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc604c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9855310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.25\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/jalcocert/Desktop/IT/Data-Chat/.venv/lib/python3.10/site-packages\n",
      "Requires: async-timeout, langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: langchain-community\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43006282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#brings your OPENAI_API_KEY\n",
    "!source .env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f80bbee",
   "metadata": {},
   "source": [
    "In this step, we’re using **BeautifulSoup’s SoupStrainer** to focus on the “content-area” class, ensuring we only extract relevant information. \n",
    "\n",
    "The WebBaseLoader then fetches and processes the specified URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231c5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class=\"markdown-body entry-content container-lg\"\n",
    "\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"markdown-body entry-content container-lg\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://github.com/JAlcocerT/Streamlit-MultiChat\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b5e7825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-text-splitters\n",
      "Version: 0.3.8\n",
      "Summary: LangChain text splitting utilities\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/jalcocert/Desktop/IT/Data-Chat/.venv/lib/python3.10/site-packages\n",
      "Requires: langchain-core\n",
      "Required-by: langchain\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2925302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200, chunk_overlap=100, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca5f9c",
   "metadata": {},
   "source": [
    "Get Ollama ready:\n",
    "\n",
    "* https://github.com/JAlcocerT/Docker/tree/main/AI_Gen/Ollama\n",
    "\n",
    "\n",
    "```sh\n",
    "sudo docker stats ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e743559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker exec -it ollama sh\n",
    "#hostname -I \n",
    "#--->> 172.20.0.2 \n",
    "#sudo docker inspect ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a49265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama run llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77591302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama pull all-minilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ffb917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-chroma\n",
    "\n",
    "# #https://pypi.org/project/langchain-chroma/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e81d88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-chroma\n",
      "Version: 0.2.3\n",
      "Summary: An integration package connecting Chroma and LangChain\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/jalcocert/Desktop/IT/Data-Chat/.venv/lib/python3.10/site-packages\n",
      "Requires: chromadb, langchain-core, numpy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a93646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_535655/1148073819.py:10: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  local_embeddings = OllamaEmbeddings(model=\"all-minilm\", base_url=\"http://0.0.0.0:11434\")\n"
     ]
    }
   ],
   "source": [
    "###DEPRICATED VERSION OF DOING IT###\n",
    "\n",
    "# from langchain_community.embeddings import OllamaEmbeddings #https://python.langchain.com/docs/integrations/text_embedding/ollama/\n",
    "# from langchain_chroma import Chroma\n",
    "\n",
    "# # local_embeddings = OllamaEmbeddings(model=\"all-minilm\")\n",
    "# # vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)\n",
    "\n",
    "# from langchain_community.embeddings import OllamaEmbeddings\n",
    "# #local_embeddings = OllamaEmbeddings(model=\"all-minilm\", base_url=\"http://192.168.0.12:11434\")\n",
    "# #local_embeddings = OllamaEmbeddings(model=\"all-minilm\", base_url=\"http://192.168.1.5:11434\")\n",
    "# local_embeddings = OllamaEmbeddings(model=\"all-minilm\", base_url=\"http://0.0.0.0:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7825019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #https://pypi.org/project/langchain-ollama/\n",
    "# !pip install langchain-ollama==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44a044df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-ollama\n",
      "Version: 0.3.2\n",
      "Summary: An integration package connecting Ollama and LangChain\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/jalcocert/Desktop/IT/Data-Chat/.venv/lib/python3.10/site-packages\n",
      "Requires: langchain-core, ollama\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5572b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "#Using a local embedding model\n",
    "#https://ollama.com/library/all-minilm\n",
    "\n",
    "# local_embeddings = OllamaEmbeddings(model=\"all-minilm\")\n",
    "# vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)\n",
    "\n",
    "# local_embeddings = OllamaEmbeddings(model=\"all-minilm\", base_url=\"http://192.168.0.12:11434\")\n",
    "# local_embeddings = OllamaEmbeddings(model=\"all-minilm\", base_url=\"http://192.168.1.5:11434\")\n",
    "local_embeddings = OllamaEmbeddings(model=\"all-minilm\", base_url=\"http://0.0.0.0:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06a073ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9635f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is the repository about?\"\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "retrieved_docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c541ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ' '.join([doc.page_content for doc in retrieved_docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87472e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Streamlit-MultiChat\\n\\n\\nMany LLMs - One Streamlit Web App\\n\\n\\nOpenAI | Anthropic | Ollama | Groq\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nA custom Streamlit Web App to Chat with the latest LLMs and get a per use cost instead of a fixed monthly price.\\nFeatures\\nUse many large language models: OpenAI, Anthropic, Open / Local LLM\\'s with one Streamlit Web App.\\n\\nLLM Support\\n\\nOllama - Open Source Models\\nOpenAI - GPT 3.5 / GPT4 / GPT4o / GPT4o-mini\\nAnthropic - Claude 3 (Opus / Sonnet) / Claude 3.5\\nGroq API - LlaMa models using quick LPU inference\\n\\n\\nExtended explanation\\n\\nSliDev presentation of the Streamlit-MultiChat\\nThis blog post →\\nDeploy as per https://github.com/JAlcocerT/Streamlit-MultiChat/tree/main/Z_DeployMe\\n\\n\\n\\nDuring the process, I also explored: SliDev PPTs, ScrapeGraph, DaLLe, Streamlit Auth and OpenAI as Custom Agents\\nGetting Started\\nThe Project is documented here →\\n\\nClone the repository and Run with your API keys 👇\\n  \\xa0\\n\\nOpenAI API Keys - https://platform.openai.com/api-keys\\nAnthropic - https://console.anthropic.com/settings/keys\\nGroq - https://console.groq.com/keys\\nFor Ollama, you need this setup\\n\\nTry the Project quickly with Python Venv\\'s:\\n\\nGet Python Installed\\nPrepare a Venv You will need Docker ready. And optionally Portainer\\n\\n\\nThanks to ❤️\\nProjects I got inspiration from / consolidated in this App were tested here: ./Z_Tests\\n\\nCheck the Projects 👈\\n  \\xa0\\n\\n\\nhttps://github.com/dataprofessor/openai-chatbot\\n\\n\\nhttps://github.com/AIDevBytes/Streamlit-Ollama-Chatbot\\n\\n\\nhttps://github.com/tonykipkemboi/groq_streamlit_demo -> Groq + Streamlit Chat\\n\\n\\nhttps://github.com/TirendazAcademy/Streamlit-Tutorials/blob/main/Blog-Generator-App-with-Claude-API/app.py\\n\\nhttps://www.youtube.com/watch?v=ximj9QWle-g\\n\\n\\n\\nhttps://github.com/siddhardhan23/gemini-pro-streamlit-chatbot Try the Project quickly with Python Venv\\'s:\\n\\nGet Python Installed\\nPrepare a Venv\\n\\ngit clone https://github.com/JAlcocerT/Streamlit-MultiChat\\n#python -m venv multichat_venv #create the venv\\npython3 -m venv multichat_venv #linux\\n\\n#multichat_venv\\\\Scripts\\\\activate #activate venv (windows)\\nsource multichat_venv/bin/activate #(linux)\\nThen, provide the API Keys and run the Streamlit Web App:\\n#uv pip install -r requirements.txt\\npip install -r requirements.txt #all at once, ~2min\\n\\ncp ./.streamlit/secrets_sample.toml ./.streamlit/secrets.toml #fill the API Keys\\nstreamlit run Z_multichat.py\\n\\nMake sure to have Ollama ready and running your desired model!\\nPrepare the API Keys in any of:\\n\\n.streamlit/secrets.toml\\nAs Environment Variables\\n\\nLinux - export OPENAI_API_KEY=\"YOUR_API_KEY\"\\nCMD - set OPENAI_API_KEY=YOUR_API_KEY\\nPS - $env:OPENAI_API_KEY=\"YOUR_API_KEY\"\\nIn the Docker-Compose\\n\\n\\nThrough the Streamlit UI\\n\\n\\n\\n\\n\\n\\nChat with Several Models with Streamlit\\n\\n\\nAlternatively - Use the Docker Image\\n\\ndocker pull ghcr.io/jalcocert/streamlit-multichat:latest #x86/ARM64\\n\\nYou will need Docker ready. And optionally Portainer'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8864686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-ollama\n",
    "#0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa3586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://python.langchain.com/api_reference/ollama/index.html\n",
    "\n",
    "# from langchain_ollama.llms import OllamaLLM\n",
    "# llm = OllamaLLM(model=\"llama3.2:1b\")\n",
    "\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "#!ollama pull llama3.2:1b\n",
    "#!ollama list\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\", base_url=\"http://0.0.0.0:11434\")\n",
    "#llm = OllamaLLM(model=\"llama3.2:1b\", base_url=\"http://192.168.0.12:11434\") #workin with LLama3.2\n",
    "#llm = OllamaLLM(model=\"all-minilm\", base_url=\"http://0.0.0.0:11434\") #not working with this model, as it is a embedding model!!!\n",
    "\n",
    "\n",
    "response = llm.invoke(f\"\"\"Answer the question according to the context given very briefly:\n",
    "           Question: {question}.\n",
    "           Context: {context}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "070934da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are several oversold and overbought periods:\\n\\n- Overbought: The Relative Strength Index (RSI) is above 70 (30-70)\\n- Oversold: The Relative Strength Index (RSI) is below 30 (70-30)\\n\\nThese levels can be used to generate buy or sell signals based on technical analysis strategies.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "586a4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_openai==0.3.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80adc1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export OPENAI_API_KEY=\"your-api-key\"\n",
    "#source .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1240af03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available OpenAI Models:\n",
      "- gpt-4o-audio-preview-2024-12-17\n",
      "- dall-e-3\n",
      "- dall-e-2\n",
      "- gpt-4o-audio-preview-2024-10-01\n",
      "- gpt-4-turbo-preview\n",
      "- text-embedding-3-small\n",
      "- gpt-4-turbo\n",
      "- gpt-4-turbo-2024-04-09\n",
      "- gpt-4.1-nano\n",
      "- gpt-4.1-nano-2025-04-14\n",
      "- gpt-4o-realtime-preview-2024-10-01\n",
      "- gpt-4o-realtime-preview\n",
      "- babbage-002\n",
      "- gpt-4\n",
      "- text-embedding-ada-002\n",
      "- chatgpt-4o-latest\n",
      "- gpt-4o-realtime-preview-2024-12-17\n",
      "- gpt-4o-mini-audio-preview\n",
      "- gpt-4o-audio-preview\n",
      "- o1-preview-2024-09-12\n",
      "- gpt-4o-mini-realtime-preview\n",
      "- gpt-4.1-mini\n",
      "- gpt-4o-mini-realtime-preview-2024-12-17\n",
      "- gpt-3.5-turbo-instruct-0914\n",
      "- gpt-4o-mini-search-preview\n",
      "- gpt-4.1-mini-2025-04-14\n",
      "- o1\n",
      "- o1-2024-12-17\n",
      "- davinci-002\n",
      "- gpt-3.5-turbo-1106\n",
      "- gpt-4o-search-preview\n",
      "- gpt-4-1106-preview\n",
      "- gpt-3.5-turbo-instruct\n",
      "- gpt-3.5-turbo\n",
      "- gpt-4o-mini-search-preview-2025-03-11\n",
      "- gpt-4-0125-preview\n",
      "- gpt-4o-2024-11-20\n",
      "- whisper-1\n",
      "- gpt-4o-2024-05-13\n",
      "- o1-pro\n",
      "- gpt-3.5-turbo-16k\n",
      "- gpt-image-1\n",
      "- o1-pro-2025-03-19\n",
      "- o1-preview\n",
      "- gpt-4-0613\n",
      "- text-embedding-3-large\n",
      "- gpt-4o-mini-tts\n",
      "- gpt-4o-transcribe\n",
      "- gpt-4.5-preview\n",
      "- gpt-4.5-preview-2025-02-27\n",
      "- gpt-4o-mini-transcribe\n",
      "- gpt-4o-search-preview-2025-03-11\n",
      "- omni-moderation-2024-09-26\n",
      "- o3-mini\n",
      "- o3-mini-2025-01-31\n",
      "- tts-1-hd\n",
      "- gpt-4o\n",
      "- tts-1-hd-1106\n",
      "- gpt-4o-mini\n",
      "- gpt-4o-2024-08-06\n",
      "- gpt-4.1\n",
      "- gpt-4.1-2025-04-14\n",
      "- gpt-4o-mini-2024-07-18\n",
      "- o1-mini\n",
      "- gpt-4o-mini-audio-preview-2024-12-17\n",
      "- gpt-3.5-turbo-0125\n",
      "- o1-mini-2024-09-12\n",
      "- tts-1\n",
      "- tts-1-1106\n",
      "- omni-moderation-latest\n",
      "- o4-mini-2025-04-16\n",
      "- o4-mini\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Configure your OpenAI API key (if not set as environment variable)\n",
    "# openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "try:\n",
    "    models = openai.models.list()\n",
    "    model_names = [model.id for model in models.data]\n",
    "    print(\"Available OpenAI Models:\")\n",
    "    for name in model_names:\n",
    "        print(f\"- {name}\")\n",
    "except openai.error.AuthenticationError as e:\n",
    "    print(f\"Authentication error: {e}\")\n",
    "    print(\"Please ensure your OPENAI_API_KEY environment variable is set correctly.\")\n",
    "except openai.error.OpenAIError as e:\n",
    "    print(f\"An OpenAI API error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "426db8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "# You'll need your OpenAI API key\n",
    "# It can be set as an environment variable OPENAI_API_KEY=your_key\n",
    "# Or passed directly as a parameter:\n",
    "\n",
    "\n",
    "\n",
    "#llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\") # Or any other OpenAI model\n",
    "llm = OpenAI(model_name=\"gpt-4.1-nano\")\n",
    "\n",
    "response = llm.invoke(f\"\"\"Answer the question according to the context given very briefly:\n",
    "           Question: {question}.\n",
    "           Context: {context}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "176e1a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-openai\n",
      "Version: 0.3.16\n",
      "Summary: An integration package connecting OpenAI and LangChain\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/jalcocert/Desktop/IT/Data-Chat/.venv/lib/python3.10/site-packages\n",
      "Requires: langchain-core, openai, tiktoken\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20b6f129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. The repository is about a Streamlit web app that allows users to chat with multiple large language models (LLMs) from various providers like OpenAI, Anthropic, Ollama, and Groq, and compare costs on a per-use basis.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9249b3a5",
   "metadata": {},
   "source": [
    "## All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce58ec8",
   "metadata": {},
   "source": [
    "### LangChain + Chroma + OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8961b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3937115a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d95a720",
   "metadata": {},
   "source": [
    "### LangChain + Chroma + Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55ecb101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what are the oversold and overbought periods?\n",
      "Answer: - Oversold: Below 20 \n",
      "- Overbought: Above 80\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "#from langchain.chains import RetrievalQA\n",
    "\n",
    "def get_response_from_website_with_chunks(\n",
    "    ollama_base_url: str,\n",
    "    embedding_model_name: str,\n",
    "    llm_model_name: str,\n",
    "    question: str,\n",
    "    website_url: str,\n",
    "    content_class: str = \"content-area\",\n",
    "    chunk_size: int = 1200,\n",
    "    chunk_overlap: int = 100,\n",
    "    search_kwargs_k: int = 3\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Scrapes a website, creates embeddings using Ollama,\n",
    "    stores them in Chroma, retrieves relevant chunks, and\n",
    "    answers a question using an Ollama language model,\n",
    "    following the provided code chunk structure.\n",
    "\n",
    "    Args:\n",
    "        ollama_base_url: The base URL of your Ollama server (e.g., \"http://localhost:11434\").\n",
    "        embedding_model_name: The name of the Ollama embedding model (e.g., \"all-minilm\").\n",
    "        llm_model_name: The name of the Ollama language model to use (e.g., \"llama3.2:1b\").\n",
    "        question: The question you want to ask about the website content.\n",
    "        website_url: The URL of the website to process.\n",
    "        content_class: The CSS class name of the main content area on the website.\n",
    "        chunk_size: The size of each text chunk.\n",
    "        chunk_overlap: The overlap between adjacent text chunks.\n",
    "        search_kwargs_k: The number of top documents to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        A string containing the answer to the question based on the website content.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Web Scraping with LangChain\n",
    "        bs4_strainer = bs4.SoupStrainer(class_=(content_class))\n",
    "        loader = WebBaseLoader(\n",
    "            web_paths=(website_url,),\n",
    "            bs_kwargs={\"parse_only\": bs4_strainer},\n",
    "        )\n",
    "        docs = loader.load()\n",
    "\n",
    "        # Step 2: Text Splitting for Manageable Chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size, chunk_overlap=chunk_overlap, add_start_index=True\n",
    "        )\n",
    "        all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "        # Step 3: Generating Embeddings with Ollama and Chroma\n",
    "        local_embeddings = OllamaEmbeddings(base_url=ollama_base_url, model=embedding_model_name)\n",
    "        vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)\n",
    "\n",
    "        # Step 4: Implementing the Retrieval System\n",
    "        retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": search_kwargs_k})\n",
    "        retrieved_docs = retriever.invoke(question)\n",
    "        context = ' '.join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "        # Step 5: Generating Responses with a Language Model\n",
    "        llm = OllamaLLM(base_url=ollama_base_url, model=llm_model_name)\n",
    "        response = llm.invoke(f\"\"\"Answer the question according to the context given very briefly:\n",
    "                   Question: {question}.\n",
    "                   Context: {context}\n",
    "        \"\"\")\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ollama_url = \"http://192.168.0.12:11434\"  # Replace with your Ollama server URL if different\n",
    "    embedding_model = \"all-minilm\"\n",
    "    llm_model = \"llama3.2:1b\"\n",
    "    user_question = \"what are the oversold and overbought periods?\"\n",
    "    target_website = \"https://pythonology.eu/using-pandas_ta-to-generate-technical-indicators-and-signals/\"\n",
    "    content_area_class = \"content-area\" # Use the same class as in the example\n",
    "\n",
    "    answer = get_response_from_website_with_chunks(\n",
    "        ollama_url,\n",
    "        embedding_model,\n",
    "        llm_model,\n",
    "        user_question,\n",
    "        target_website,\n",
    "        content_class=content_area_class\n",
    "    )\n",
    "    print(f\"Question: {user_question}\")\n",
    "    print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15e46379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements-export.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
