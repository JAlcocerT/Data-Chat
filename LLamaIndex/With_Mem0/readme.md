* https://pypi.org/project/mem0ai/
* https://pypi.org/project/llama-index/


<div align="center">
  <a href="https://www.python.org/downloads/release/python-310">
    <img alt="Python Version" src="https://img.shields.io/badge/python-3.10-blue.svg" />
  </a>
</div>

* API's needed:
  * https://www.anthropic.com/api
  * https://platform.openai.com/

## Chat_with_md

* The **Anthropic model** isn't used directly for generating responses to user questions, it is used indirectly through the `Llama Index` for finding **relevant property documents** based on the user's previous questions.
  * [llama_index.llms.anthropic](https://docs.llamaindex.ai/en/stable/examples/llm/anthropic/)
  * https://docs.anthropic.com/en/docs/about-claude/models

* The **responses** to the user's questions are generated by the **OpenAI's GPT-4 model**. 
  * The `ask_question` method, the OpenAI client is used to create a chat completion with the GPT-4 model. The current conversation history (self.messages) is passed to the model, which generates a response. The response is then added to the conversation history.
  * https://platform.openai.com/docs/api-reference/introduction